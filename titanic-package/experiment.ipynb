{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bigger-wealth",
   "metadata": {},
   "source": [
    "# Experiments with Titanic data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-expert",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to build a ML model for titanic survivor prediction. \n",
    "\n",
    "We are going to build a basic model using sklearn. The purpose is to experiment with feature engineering and try few models to pick the best. \n",
    "Once we are happy with the processing and model building parts of our code, we are going to create a package of our code and execute this on AI platform training service.\n",
    "\n",
    "!The packageing and execution to AI Platform is not part of this notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "imperial-iceland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dask[dataframe] in /opt/conda/lib/python3.7/site-packages (2021.2.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from dask[dataframe]) (5.4.1)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from dask[dataframe]) (0.8.5)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /opt/conda/lib/python3.7/site-packages (from dask[dataframe]) (0.11.1)\n",
      "Requirement already satisfied: partd>=0.3.10 in /opt/conda/lib/python3.7/site-packages (from dask[dataframe]) (1.1.0)\n",
      "Requirement already satisfied: pandas>=0.25.0 in /opt/conda/lib/python3.7/site-packages (from dask[dataframe]) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.15.1 in /opt/conda/lib/python3.7/site-packages (from dask[dataframe]) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.25.0->dask[dataframe]) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.25.0->dask[dataframe]) (2021.1)\n",
      "Requirement already satisfied: locket in /opt/conda/lib/python3.7/site-packages (from partd>=0.3.10->dask[dataframe]) (0.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=0.25.0->dask[dataframe]) (1.15.0)\n",
      "Requirement already satisfied: explainerdashboard in /opt/conda/lib/python3.7/site-packages (0.3.3.1)\n",
      "Requirement already satisfied: waitress in /opt/conda/lib/python3.7/site-packages (from explainerdashboard) (2.0.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from explainerdashboard) (7.1.2)\n",
      "Requirement already satisfied: oyaml in /opt/conda/lib/python3.7/site-packages (from explainerdashboard) (1.0)\n",
      "Requirement already satisfied: pandas>=1.1 in /opt/conda/lib/python3.7/site-packages (from explainerdashboard) (1.2.1)\n",
      "Requirement already satisfied: flask-simplelogin in /opt/conda/lib/python3.7/site-packages (from explainerdashboard) (0.0.7)\n",
      "Requirement already satisfied: shap>=0.37 in /opt/conda/lib/python3.7/site-packages (from explainerdashboard) (0.39.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from explainerdashboard) (0.24.1)\n",
      "Requirement already satisfied: dash-bootstrap-components in /opt/conda/lib/python3.7/site-packages (from explainerdashboard) (0.12.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from explainerdashboard) (1.19.5)\n",
      "Requirement already satisfied: jupyter-dash in /opt/conda/lib/python3.7/site-packages (from explainerdashboard) (0.4.0)\n",
      "Requirement already satisfied: dash>=1.19 in /opt/conda/lib/python3.7/site-packages (from explainerdashboard) (1.19.0)\n",
      "Requirement already satisfied: dash-auth in /opt/conda/lib/python3.7/site-packages (from explainerdashboard) (1.4.1)\n",
      "Requirement already satisfied: dtreeviz>=1.1.4 in /opt/conda/lib/python3.7/site-packages (from explainerdashboard) (1.2)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from explainerdashboard) (1.0.0)\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.7/site-packages (from dash>=1.19->explainerdashboard) (4.14.3)\n",
      "Requirement already satisfied: Flask>=1.0.4 in /opt/conda/lib/python3.7/site-packages (from dash>=1.19->explainerdashboard) (1.1.2)\n",
      "Requirement already satisfied: dash-core-components==1.15.0 in /opt/conda/lib/python3.7/site-packages (from dash>=1.19->explainerdashboard) (1.15.0)\n",
      "Requirement already satisfied: dash-table==4.11.2 in /opt/conda/lib/python3.7/site-packages (from dash>=1.19->explainerdashboard) (4.11.2)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from dash>=1.19->explainerdashboard) (0.18.2)\n",
      "Requirement already satisfied: dash-renderer==1.9.0 in /opt/conda/lib/python3.7/site-packages (from dash>=1.19->explainerdashboard) (1.9.0)\n",
      "Requirement already satisfied: flask-compress in /opt/conda/lib/python3.7/site-packages (from dash>=1.19->explainerdashboard) (1.9.0)\n",
      "Requirement already satisfied: dash-html-components==1.1.2 in /opt/conda/lib/python3.7/site-packages (from dash>=1.19->explainerdashboard) (1.1.2)\n",
      "Requirement already satisfied: pytest in /opt/conda/lib/python3.7/site-packages (from dtreeviz>=1.1.4->explainerdashboard) (6.2.2)\n",
      "Requirement already satisfied: colour in /opt/conda/lib/python3.7/site-packages (from dtreeviz>=1.1.4->explainerdashboard) (0.1.5)\n",
      "Requirement already satisfied: graphviz>=0.9 in /opt/conda/lib/python3.7/site-packages (from dtreeviz>=1.1.4->explainerdashboard) (0.16)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from dtreeviz>=1.1.4->explainerdashboard) (3.3.4)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/conda/lib/python3.7/site-packages (from Flask>=1.0.4->dash>=1.19->explainerdashboard) (1.0.1)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /opt/conda/lib/python3.7/site-packages (from Flask>=1.0.4->dash>=1.19->explainerdashboard) (2.11.3)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/lib/python3.7/site-packages (from Flask>=1.0.4->dash>=1.19->explainerdashboard) (1.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from Jinja2>=2.10.1->Flask>=1.0.4->dash>=1.19->explainerdashboard) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.1->explainerdashboard) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.1->explainerdashboard) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=1.1->explainerdashboard) (1.15.0)\n",
      "Requirement already satisfied: numba in /opt/conda/lib/python3.7/site-packages (from shap>=0.37->explainerdashboard) (0.52.0)\n",
      "Requirement already satisfied: slicer==0.0.7 in /opt/conda/lib/python3.7/site-packages (from shap>=0.37->explainerdashboard) (0.0.7)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.7/site-packages (from shap>=0.37->explainerdashboard) (1.6.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from shap>=0.37->explainerdashboard) (1.6.0)\n",
      "Requirement already satisfied: tqdm>4.25.0 in /opt/conda/lib/python3.7/site-packages (from shap>=0.37->explainerdashboard) (4.56.0)\n",
      "Requirement already satisfied: chart-studio>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from dash-auth->explainerdashboard) (1.1.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from dash-auth->explainerdashboard) (2.25.1)\n",
      "Requirement already satisfied: flask-seasurf in /opt/conda/lib/python3.7/site-packages (from dash-auth->explainerdashboard) (0.3.0)\n",
      "Requirement already satisfied: ua-parser in /opt/conda/lib/python3.7/site-packages (from dash-auth->explainerdashboard) (0.10.0)\n",
      "Requirement already satisfied: retrying in /opt/conda/lib/python3.7/site-packages (from dash-auth->explainerdashboard) (1.3.3)\n",
      "Requirement already satisfied: brotli in /opt/conda/lib/python3.7/site-packages (from flask-compress->dash>=1.19->explainerdashboard) (1.0.9)\n",
      "Requirement already satisfied: flask_wtf in /opt/conda/lib/python3.7/site-packages (from flask-simplelogin->explainerdashboard) (0.14.3)\n",
      "Requirement already satisfied: WTForms in /opt/conda/lib/python3.7/site-packages (from flask_wtf->flask-simplelogin->explainerdashboard) (2.3.3)\n",
      "Requirement already satisfied: ansi2html in /opt/conda/lib/python3.7/site-packages (from jupyter-dash->explainerdashboard) (1.6.0)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.7/site-packages (from jupyter-dash->explainerdashboard) (5.3.4)\n",
      "Requirement already satisfied: ipython in /opt/conda/lib/python3.7/site-packages (from jupyter-dash->explainerdashboard) (7.20.0)\n",
      "Requirement already satisfied: tornado>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipykernel->jupyter-dash->explainerdashboard) (6.1)\n",
      "Requirement already satisfied: traitlets>=4.1.0 in /opt/conda/lib/python3.7/site-packages (from ipykernel->jupyter-dash->explainerdashboard) (5.0.5)\n",
      "Requirement already satisfied: jupyter-client in /opt/conda/lib/python3.7/site-packages (from ipykernel->jupyter-dash->explainerdashboard) (6.1.11)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.7/site-packages (from ipython->jupyter-dash->explainerdashboard) (4.8.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.7/site-packages (from ipython->jupyter-dash->explainerdashboard) (0.18.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython->jupyter-dash->explainerdashboard) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.7/site-packages (from ipython->jupyter-dash->explainerdashboard) (49.6.0.post20210108)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython->jupyter-dash->explainerdashboard) (3.0.14)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython->jupyter-dash->explainerdashboard) (4.4.2)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython->jupyter-dash->explainerdashboard) (2.7.4)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython->jupyter-dash->explainerdashboard) (0.7.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.16->ipython->jupyter-dash->explainerdashboard) (0.8.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect>4.3->ipython->jupyter-dash->explainerdashboard) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->jupyter-dash->explainerdashboard) (0.2.5)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.7/site-packages (from traitlets>=4.1.0->ipykernel->jupyter-dash->explainerdashboard) (0.2.0)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /opt/conda/lib/python3.7/site-packages (from jupyter-client->ipykernel->jupyter-dash->explainerdashboard) (4.7.1)\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.7/site-packages (from jupyter-client->ipykernel->jupyter-dash->explainerdashboard) (22.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.7/site-packages (from matplotlib->dtreeviz>=1.1.4->explainerdashboard) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->dtreeviz>=1.1.4->explainerdashboard) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->dtreeviz>=1.1.4->explainerdashboard) (8.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->dtreeviz>=1.1.4->explainerdashboard) (0.10.0)\n",
      "Requirement already satisfied: llvmlite<0.36,>=0.35.0 in /opt/conda/lib/python3.7/site-packages (from numba->shap>=0.37->explainerdashboard) (0.35.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from oyaml->explainerdashboard) (5.4.1)\n",
      "Requirement already satisfied: toml in /opt/conda/lib/python3.7/site-packages (from pytest->dtreeviz>=1.1.4->explainerdashboard) (0.10.2)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest->dtreeviz>=1.1.4->explainerdashboard) (3.4.0)\n",
      "Requirement already satisfied: py>=1.8.2 in /opt/conda/lib/python3.7/site-packages (from pytest->dtreeviz>=1.1.4->explainerdashboard) (1.10.0)\n",
      "Requirement already satisfied: pluggy<1.0.0a1,>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest->dtreeviz>=1.1.4->explainerdashboard) (0.13.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from pytest->dtreeviz>=1.1.4->explainerdashboard) (20.8)\n",
      "Requirement already satisfied: iniconfig in /opt/conda/lib/python3.7/site-packages (from pytest->dtreeviz>=1.1.4->explainerdashboard) (1.1.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.7/site-packages (from pytest->dtreeviz>=1.1.4->explainerdashboard) (20.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest->dtreeviz>=1.1.4->explainerdashboard) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest->dtreeviz>=1.1.4->explainerdashboard) (3.7.4.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->dash-auth->explainerdashboard) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->dash-auth->explainerdashboard) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->dash-auth->explainerdashboard) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->dash-auth->explainerdashboard) (1.26.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->explainerdashboard) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install dask[dataframe]\n",
    "!pip install explainerdashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "prime-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all necessary modules needed for our ML process\n",
    "\n",
    "#import google.auth\n",
    "import dask.dataframe as dd\n",
    "from google.cloud import bigquery, bigquery_storage\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt  \n",
    "import pickle\n",
    "from google.cloud import storage\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "import numpy as np\n",
    "from typing import Union, List\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-partnership",
   "metadata": {},
   "source": [
    "Here we set the PROJECT variable to our project id. The project id can be found on your GCP console but the following automates the process by getting the value from !gcloud config get-value project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "compliant-geography",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT=!gcloud config get-value project # returns default project id \n",
    "PROJECT=PROJECT[0]\n",
    "\n",
    "BUCKET = \"gs://\"+PROJECT\n",
    "\n",
    "DATA_GCS_LOCATION = BUCKET+\"/titanic/data_v1.csv\"\n",
    "DATA_BQ_URI = 'bq://'+PROJECT+'.titanic.survivors'\n",
    "\n",
    "JOB_TIMESTAMP = datetime.now().strftime('%Y%m%d-%H%M%S') # Creating timestamp so that every execution of the notebook writes to a unique gs location\n",
    "\n",
    "MODEL_DIR = BUCKET+\"/titanic/experiment-\"+JOB_TIMESTAMP # adding the timestamp to the model_dir path.\n",
    "                                                        # This path is used to write assets like the trained model and job report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "indirect-round",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantitative-france",
   "metadata": {},
   "source": [
    "## Loading data from Google Cloud Storage (GCS) to Pandas Dataframe\n",
    "\n",
    "In the following cell we are pulling data from GCS and loading them to a dataframe. Keep in mind that data might not fit your instance memory and therefore we might need to only bring a sample of the data. That is not a big problem as we are only experimenting. When we will be running our training job on AI Platform training we need to pick the right instance with enough memory.\n",
    "\n",
    "Additionally our telco dataset fits the memory so we will go ahead and load everything.\n",
    "\n",
    "Finally we will be using Dask (https://docs.dask.org/en/latest/) to load our data to Pandas. Dask is a library that allows parallelism of varius operations like data processing and ML training. In our case we want to leverage the ability of loading data using a wild card. If your data are in multible files wild cards allows you to define the the singniture of the data file path and load multiple files. \n",
    "\n",
    "for example if you have:\n",
    "* gs://my_bucket/training-data/part-1.csv\n",
    "* gs://my_bucket/training-data/part-2.csv\n",
    "* gs://my_bucket/training-data/part-3.csv\n",
    "    \n",
    "you can use the following wild card to load all:\n",
    "*  gs://my_bucket/training-data/part-*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "champion-arlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data_from_gcs(data_gcs_path: str) -> pd.DataFrame:\n",
    "    '''\n",
    "    Loads data from Google Cloud Storage (GCS) to a dataframe\n",
    "\n",
    "            Parameters:\n",
    "                    data_gcs_path (str): gs path for the location of the data. Wildcards are also supported. i.e gs://example_bucket/data/training-*.csv\n",
    "\n",
    "            Returns:\n",
    "                    pandas.DataFrame: a dataframe with the data from GCP loaded\n",
    "    '''\n",
    "        \n",
    "    # using dask that supports wildcards to read multiple files. Then with dd.read_csv().compute we create a pandas dataframe\n",
    "    # Additionally I have noticed that some values for TotalCharges are missing and this creates confusion regarding TotalCharges the data types. \n",
    "    # to overcome this we manually define TotalCharges as object. \n",
    "    # We will later fix this upnormality\n",
    "    logging.info(\"reading gs data: {}\".format(data_gcs_path))\n",
    "    return dd.read_csv(data_gcs_path, dtype={'TotalCharges': 'object'}).compute()\n",
    "\n",
    "# This is not used at this tutorial but it is here to demonstrate how loading data directly from big query looks like\n",
    "def load_data_from_bq(bq_uri: str) -> pd.DataFrame:\n",
    "    '''\n",
    "    Loads data from BigQuery table (BQ) to a dataframe\n",
    "\n",
    "            Parameters:\n",
    "                    bq_uri (str): bq table uri. i.e: example_project.example_dataset.example_table\n",
    "            Returns:\n",
    "                    pandas.DataFrame: a dataframe with the data from GCP loaded\n",
    "    '''\n",
    "    if not bq_uri.startswith('bq://'):\n",
    "        raise Exception(\"uri is not a BQ uri. It should be bq://project_id.dataset.table\")\n",
    "    logging.info(\"reading bq data: {}\".format(bq_uri))\n",
    "    project,dataset,table =  bq_uri.split(\".\")\n",
    "    bqclient = bigquery.Client(project=project[5:])\n",
    "    bqstorageclient = bigquery_storage.BigQueryReadClient()\n",
    "    query_string = \"\"\"\n",
    "    SELECT * from {ds}.{tbl}\n",
    "    \"\"\".format(ds=dataset, tbl=table)\n",
    "\n",
    "    return (\n",
    "        bqclient.query(query_string)\n",
    "        .result()\n",
    "        .to_dataframe(bqstorage_client=bqstorageclient)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "waiting-devices",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data_from_bq(DATA_BQ_URI)\n",
    "#df = load_data_from_gcs(DATA_GCS_LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-special",
   "metadata": {},
   "source": [
    "Let's have a look how the data loaded in the dataframe look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "southeast-complement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['pclass', 'survived', 'name', 'sex', 'age', 'sibsp', 'parch', 'ticket',\n",
      "       'fare', 'cabin', 'embarked', 'boat', 'body', 'home_dest'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home_dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Salomon, Mr. Abraham L</td>\n",
       "      <td>male</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111163</td>\n",
       "      <td>26</td>\n",
       "      <td>?</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Duff Gordon, Lady. (Lucille Christiana Sutherl...</td>\n",
       "      <td>female</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11755</td>\n",
       "      <td>39.6</td>\n",
       "      <td>A16</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>London / Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Stengel, Mr. Charles Emil Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11778</td>\n",
       "      <td>55.4417</td>\n",
       "      <td>C116</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>Newark, NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Duff Gordon, Sir. Cosmo Edmund ('Mr Morgan')</td>\n",
       "      <td>male</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17485</td>\n",
       "      <td>56.9292</td>\n",
       "      <td>A20</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>London / Paris</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                               name  \\\n",
       "0       1         1                             Salomon, Mr. Abraham L   \n",
       "1       1         1  Duff Gordon, Lady. (Lucille Christiana Sutherl...   \n",
       "2       1         1                    Stengel, Mr. Charles Emil Henry   \n",
       "3       1         1       Duff Gordon, Sir. Cosmo Edmund ('Mr Morgan')   \n",
       "\n",
       "      sex age  sibsp  parch    ticket     fare cabin embarked boat body  \\\n",
       "0    male   ?      0      0    111163       26     ?        S    1    ?   \n",
       "1  female  48      1      0     11755     39.6   A16        C    1    ?   \n",
       "2    male  54      1      0     11778  55.4417  C116        C    1    ?   \n",
       "3    male  49      1      0  PC 17485  56.9292   A20        C    1    ?   \n",
       "\n",
       "        home_dest  \n",
       "0    New York, NY  \n",
       "1  London / Paris  \n",
       "2      Newark, NJ  \n",
       "3  London / Paris  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.columns) # Print all columns in the dataframe\n",
    "df.head(4) # Show my the first 4 records of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-fleece",
   "metadata": {},
   "source": [
    "## Define Features Types\n",
    "Define the different features types you have in the following categories. The feature names need to match the column names in your CSV file.\n",
    "Do not include any columns that you want to drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "cardiovascular-thermal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature categories\n",
    "\n",
    "# List all binary features: 0,1 or True,Fales or Male,Female etc\n",
    "BINARY_FEATURES = [\n",
    "    'sex']\n",
    "\n",
    "# List all numeric features\n",
    "NUMERIC_FEATURES = [\n",
    "    'age',\n",
    "    'fare']\n",
    "\n",
    "# List all categorical features \n",
    "CATEGORICAL_FEATURES = [\n",
    "    'pclass',\n",
    "    'embarked',\n",
    "    'home_dest',\n",
    "    'parch',\n",
    "    'sibsp']\n",
    "\n",
    "ALL_COLUMNS = BINARY_FEATURES+NUMERIC_FEATURES+CATEGORICAL_FEATURES\n",
    "\n",
    "LABEL = 'survived'\n",
    "\n",
    "# We define the index position of each feature. This will be needed when we wil be processing a \n",
    "# numpy array (instead of pandas) that has no column names.\n",
    "BINARY_FEATURES_IDX = list(range(0,len(BINARY_FEATURES)))\n",
    "NUMERIC_FEATURES_IDX = list(range(len(BINARY_FEATURES), len(BINARY_FEATURES)+len(NUMERIC_FEATURES)))\n",
    "CATEGORICAL_FEATURES_IDX = list(range(len(BINARY_FEATURES+NUMERIC_FEATURES), len(ALL_COLUMNS)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-contrast",
   "metadata": {},
   "source": [
    "## Data Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-disaster",
   "metadata": {},
   "source": [
    "It seems that there are some invalid values in TotalCharges column where the TotalCharges is missing. Look at the first record below, data are order based on TotalCharges.\n",
    "\n",
    "Why is that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "structural-bicycle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home_dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dean, Miss. Elizabeth Gladys 'Millvina'</td>\n",
       "      <td>female</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>C.A. 2315</td>\n",
       "      <td>20.575</td>\n",
       "      <td>?</td>\n",
       "      <td>S</td>\n",
       "      <td>10</td>\n",
       "      <td>?</td>\n",
       "      <td>Devon, England Wichita, KS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Danbom, Master. Gilbert Sigvard Emanuel</td>\n",
       "      <td>male</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347080</td>\n",
       "      <td>14.4</td>\n",
       "      <td>?</td>\n",
       "      <td>S</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Stanton, IA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Thomas, Master. Assad Alexander</td>\n",
       "      <td>male</td>\n",
       "      <td>0.4167</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2625</td>\n",
       "      <td>8.5167</td>\n",
       "      <td>?</td>\n",
       "      <td>C</td>\n",
       "      <td>16</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Hamalainen, Master. Viljo</td>\n",
       "      <td>male</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>250649</td>\n",
       "      <td>14.5</td>\n",
       "      <td>?</td>\n",
       "      <td>S</td>\n",
       "      <td>4</td>\n",
       "      <td>?</td>\n",
       "      <td>Detroit, MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Baclini, Miss. Eugenie</td>\n",
       "      <td>female</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2666</td>\n",
       "      <td>19.2583</td>\n",
       "      <td>?</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>?</td>\n",
       "      <td>Syria New York, NY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pclass  survived                                     name     sex  \\\n",
       "1114       3         1  Dean, Miss. Elizabeth Gladys 'Millvina'  female   \n",
       "374        3         0  Danbom, Master. Gilbert Sigvard Emanuel    male   \n",
       "1298       3         1          Thomas, Master. Assad Alexander    male   \n",
       "50         2         1                Hamalainen, Master. Viljo    male   \n",
       "1065       3         1                   Baclini, Miss. Eugenie  female   \n",
       "\n",
       "         age  sibsp  parch     ticket     fare cabin embarked boat body  \\\n",
       "1114  0.1667      1      2  C.A. 2315   20.575     ?        S   10    ?   \n",
       "374   0.3333      0      2     347080     14.4     ?        S    ?    ?   \n",
       "1298  0.4167      0      1       2625   8.5167     ?        C   16    ?   \n",
       "50    0.6667      1      1     250649     14.5     ?        S    4    ?   \n",
       "1065    0.75      2      1       2666  19.2583     ?        C    C    ?   \n",
       "\n",
       "                       home_dest  \n",
       "1114  Devon, England Wichita, KS  \n",
       "374                  Stanton, IA  \n",
       "1298                           ?  \n",
       "50                   Detroit, MI  \n",
       "1065          Syria New York, NY  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(\"age\", ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-particle",
   "metadata": {},
   "source": [
    "hm... I suspect that the reason is that new customers do not have TotalCharges as this is their first month.\n",
    "\n",
    "We can evaluate this by looking into the min and max vlaues for each tenure. \n",
    "\n",
    "As suspected none of 0 tenure datapoints have TotalCharges set yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "cubic-sandwich",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1667</th>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3333</th>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4167</th>\n",
       "      <td>0.4167</td>\n",
       "      <td>0.4167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6667</th>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.6667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>?</th>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           min     max\n",
       "age                   \n",
       "0.1667  0.1667  0.1667\n",
       "0.3333  0.3333  0.3333\n",
       "0.4167  0.4167  0.4167\n",
       "0.6667  0.6667  0.6667\n",
       "0.75      0.75    0.75\n",
       "...        ...     ...\n",
       "76          76      76\n",
       "8            8       8\n",
       "80          80      80\n",
       "9            9       9\n",
       "?            ?       ?\n",
       "\n",
       "[99 rows x 2 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = df.groupby(['age'])\n",
    "gb['age'].agg(['min', 'max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-briefing",
   "metadata": {},
   "source": [
    "As suspected none of 0 tenure datapoints have TotalCharges set yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "unusual-maple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home_dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Salomon, Mr. Abraham L</td>\n",
       "      <td>male</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111163</td>\n",
       "      <td>26</td>\n",
       "      <td>?</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Duff Gordon, Lady. (Lucille Christiana Sutherl...</td>\n",
       "      <td>female</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11755</td>\n",
       "      <td>39.6</td>\n",
       "      <td>A16</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>London / Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Stengel, Mr. Charles Emil Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11778</td>\n",
       "      <td>55.4417</td>\n",
       "      <td>C116</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>Newark, NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Duff Gordon, Sir. Cosmo Edmund ('Mr Morgan')</td>\n",
       "      <td>male</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17485</td>\n",
       "      <td>56.9292</td>\n",
       "      <td>A20</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>London / Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Francatelli, Miss. Laura Mabel</td>\n",
       "      <td>female</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17485</td>\n",
       "      <td>56.9292</td>\n",
       "      <td>E36</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Willard, Miss. Constance</td>\n",
       "      <td>female</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113795</td>\n",
       "      <td>26.55</td>\n",
       "      <td>?</td>\n",
       "      <td>S</td>\n",
       "      <td>8 10</td>\n",
       "      <td>?</td>\n",
       "      <td>Duluth, MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Vartanian, Mr. David</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2658</td>\n",
       "      <td>7.225</td>\n",
       "      <td>?</td>\n",
       "      <td>C</td>\n",
       "      <td>13 15</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Tenglin, Mr. Gunnar Isidor</td>\n",
       "      <td>male</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350033</td>\n",
       "      <td>7.7958</td>\n",
       "      <td>?</td>\n",
       "      <td>S</td>\n",
       "      <td>13 15</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Miss. Catherine 'Katie'</td>\n",
       "      <td>female</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>383123</td>\n",
       "      <td>7.75</td>\n",
       "      <td>?</td>\n",
       "      <td>Q</td>\n",
       "      <td>15 16</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Daly, Mr. Eugene Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>382651</td>\n",
       "      <td>7.75</td>\n",
       "      <td>?</td>\n",
       "      <td>Q</td>\n",
       "      <td>13 15 B</td>\n",
       "      <td>?</td>\n",
       "      <td>Co Athlone, Ireland New York, NY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pclass  survived                                               name  \\\n",
       "0          1         1                             Salomon, Mr. Abraham L   \n",
       "1          1         1  Duff Gordon, Lady. (Lucille Christiana Sutherl...   \n",
       "2          1         1                    Stengel, Mr. Charles Emil Henry   \n",
       "3          1         1       Duff Gordon, Sir. Cosmo Edmund ('Mr Morgan')   \n",
       "4          1         1                     Francatelli, Miss. Laura Mabel   \n",
       "...      ...       ...                                                ...   \n",
       "1304       1         1                           Willard, Miss. Constance   \n",
       "1305       3         1                               Vartanian, Mr. David   \n",
       "1306       3         1                         Tenglin, Mr. Gunnar Isidor   \n",
       "1307       3         1                  McCarthy, Miss. Catherine 'Katie'   \n",
       "1308       3         1                           Daly, Mr. Eugene Patrick   \n",
       "\n",
       "         sex age  sibsp  parch    ticket     fare cabin embarked     boat  \\\n",
       "0       male   ?      0      0    111163       26     ?        S        1   \n",
       "1     female  48      1      0     11755     39.6   A16        C        1   \n",
       "2       male  54      1      0     11778  55.4417  C116        C        1   \n",
       "3       male  49      1      0  PC 17485  56.9292   A20        C        1   \n",
       "4     female  30      0      0  PC 17485  56.9292   E36        C        1   \n",
       "...      ...  ..    ...    ...       ...      ...   ...      ...      ...   \n",
       "1304  female  21      0      0    113795    26.55     ?        S     8 10   \n",
       "1305    male  22      0      0      2658    7.225     ?        C    13 15   \n",
       "1306    male  25      0      0    350033   7.7958     ?        S    13 15   \n",
       "1307  female   ?      0      0    383123     7.75     ?        Q    15 16   \n",
       "1308    male  29      0      0    382651     7.75     ?        Q  13 15 B   \n",
       "\n",
       "     body                         home_dest  \n",
       "0       ?                      New York, NY  \n",
       "1       ?                    London / Paris  \n",
       "2       ?                        Newark, NJ  \n",
       "3       ?                    London / Paris  \n",
       "4       ?                                 ?  \n",
       "...   ...                               ...  \n",
       "1304    ?                        Duluth, MN  \n",
       "1305    ?                                 ?  \n",
       "1306    ?                                 ?  \n",
       "1307    ?                                 ?  \n",
       "1308    ?  Co Athlone, Ireland New York, NY  \n",
       "\n",
       "[1309 rows x 14 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-indie",
   "metadata": {},
   "source": [
    "Okey lets fix this by assigning the values of this column to equal the MonthlyCharges. For new customers at the end of the first month the total charges should be the same as that months' charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "signed-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that \n",
    "def clean_missing_numerics(df: pd.DataFrame, numeric_columns):\n",
    "    '''\n",
    "    removes invalid values in the numeric columns        \n",
    "\n",
    "            Parameters:\n",
    "                    df (pandas.DataFrame): The Pandas Dataframe to alter \n",
    "                    numeric_columns (List[str]): List of column names that are numberic from the DataFrame\n",
    "            Returns:\n",
    "                    pandas.DataFrame: a dataframe with the numeric columns fixed\n",
    "    '''\n",
    "    \n",
    "    for n in numeric_columns:\n",
    "        df[n] = pd.to_numeric(df[n], errors='coerce')\n",
    "        \n",
    "    df = df.fillna(df.mean())\n",
    "         \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "registered-cincinnati",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home_dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Salomon, Mr. Abraham L</td>\n",
       "      <td>male</td>\n",
       "      <td>29.881135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111163</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>?</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Duff Gordon, Lady. (Lucille Christiana Sutherl...</td>\n",
       "      <td>female</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11755</td>\n",
       "      <td>39.6000</td>\n",
       "      <td>A16</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>London / Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Stengel, Mr. Charles Emil Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11778</td>\n",
       "      <td>55.4417</td>\n",
       "      <td>C116</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>Newark, NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Duff Gordon, Sir. Cosmo Edmund ('Mr Morgan')</td>\n",
       "      <td>male</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17485</td>\n",
       "      <td>56.9292</td>\n",
       "      <td>A20</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>London / Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Francatelli, Miss. Laura Mabel</td>\n",
       "      <td>female</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17485</td>\n",
       "      <td>56.9292</td>\n",
       "      <td>E36</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Willard, Miss. Constance</td>\n",
       "      <td>female</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113795</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>?</td>\n",
       "      <td>S</td>\n",
       "      <td>8 10</td>\n",
       "      <td>?</td>\n",
       "      <td>Duluth, MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Vartanian, Mr. David</td>\n",
       "      <td>male</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2658</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>?</td>\n",
       "      <td>C</td>\n",
       "      <td>13 15</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Tenglin, Mr. Gunnar Isidor</td>\n",
       "      <td>male</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350033</td>\n",
       "      <td>7.7958</td>\n",
       "      <td>?</td>\n",
       "      <td>S</td>\n",
       "      <td>13 15</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Miss. Catherine 'Katie'</td>\n",
       "      <td>female</td>\n",
       "      <td>29.881135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>383123</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>?</td>\n",
       "      <td>Q</td>\n",
       "      <td>15 16</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Daly, Mr. Eugene Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>382651</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>?</td>\n",
       "      <td>Q</td>\n",
       "      <td>13 15 B</td>\n",
       "      <td>?</td>\n",
       "      <td>Co Athlone, Ireland New York, NY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pclass  survived                                               name  \\\n",
       "0          1         1                             Salomon, Mr. Abraham L   \n",
       "1          1         1  Duff Gordon, Lady. (Lucille Christiana Sutherl...   \n",
       "2          1         1                    Stengel, Mr. Charles Emil Henry   \n",
       "3          1         1       Duff Gordon, Sir. Cosmo Edmund ('Mr Morgan')   \n",
       "4          1         1                     Francatelli, Miss. Laura Mabel   \n",
       "...      ...       ...                                                ...   \n",
       "1304       1         1                           Willard, Miss. Constance   \n",
       "1305       3         1                               Vartanian, Mr. David   \n",
       "1306       3         1                         Tenglin, Mr. Gunnar Isidor   \n",
       "1307       3         1                  McCarthy, Miss. Catherine 'Katie'   \n",
       "1308       3         1                           Daly, Mr. Eugene Patrick   \n",
       "\n",
       "         sex        age  sibsp  parch    ticket     fare cabin embarked  \\\n",
       "0       male  29.881135      0      0    111163  26.0000     ?        S   \n",
       "1     female  48.000000      1      0     11755  39.6000   A16        C   \n",
       "2       male  54.000000      1      0     11778  55.4417  C116        C   \n",
       "3       male  49.000000      1      0  PC 17485  56.9292   A20        C   \n",
       "4     female  30.000000      0      0  PC 17485  56.9292   E36        C   \n",
       "...      ...        ...    ...    ...       ...      ...   ...      ...   \n",
       "1304  female  21.000000      0      0    113795  26.5500     ?        S   \n",
       "1305    male  22.000000      0      0      2658   7.2250     ?        C   \n",
       "1306    male  25.000000      0      0    350033   7.7958     ?        S   \n",
       "1307  female  29.881135      0      0    383123   7.7500     ?        Q   \n",
       "1308    male  29.000000      0      0    382651   7.7500     ?        Q   \n",
       "\n",
       "         boat body                         home_dest  \n",
       "0           1    ?                      New York, NY  \n",
       "1           1    ?                    London / Paris  \n",
       "2           1    ?                        Newark, NJ  \n",
       "3           1    ?                    London / Paris  \n",
       "4           1    ?                                 ?  \n",
       "...       ...  ...                               ...  \n",
       "1304     8 10    ?                        Duluth, MN  \n",
       "1305    13 15    ?                                 ?  \n",
       "1306    13 15    ?                                 ?  \n",
       "1307    15 16    ?                                 ?  \n",
       "1308  13 15 B    ?  Co Athlone, Ireland New York, NY  \n",
       "\n",
       "[1309 rows x 14 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = clean_missing_numerics(df, NUMERIC_FEATURES)\n",
    "\n",
    "# Is the problem now solved?\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentic-bench",
   "metadata": {},
   "source": [
    "We do not want all our columns. customerID is unique for every customer and does not provide any information for our model.\n",
    "\n",
    "Additionaly we want to separate the label column from the training data.\n",
    "\n",
    "It is important to notice that we are also reordering the columns, Binary first, then the numeric and then the categorical ones.\n",
    "\n",
    "This is the order that the model will be accepting the features for prediction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "worthy-cache",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_selection(df: pd.DataFrame, selected_columns: List[str], label_column: str) -> (pd.DataFrame, pd.Series):\n",
    "    '''\n",
    "    From a dataframe create a new dataframe with only selected columns and returns it.\n",
    "    Additionally it splits the label column into a pandas Series.\n",
    "\n",
    "            Parameters:\n",
    "                    df (pandas.DataFrame): The Pandas Dataframe to drop columns and extract label\n",
    "                    selected_columns (List[str]): List of strings with the selected columns. i,e ['col_1', 'col_2', ..., 'col_n' ]\n",
    "                    label_column (str): The name of the label column\n",
    "\n",
    "            Returns:\n",
    "                    tuple(pandas.DataFrame, pandas.Series): Tuble with the new pandas DataFrame containing only selected columns and lablel pandas Series\n",
    "    '''\n",
    "    # We create a series with the prediciton label\n",
    "    labels = df[label_column]\n",
    "    \n",
    "    data = df.loc[:, selected_columns]\n",
    "    \n",
    "\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "fabulous-match",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data_selection(df, ALL_COLUMNS, LABEL);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-cleaners",
   "metadata": {},
   "source": [
    "We need to split our data sto training and test sets and also select only the columns that we need to use in our training routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "proved-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-pennsylvania",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "We have columns in multible formats. Some are numerical, some are binary categorical having only 2 values, and some are categorical with multiple options.\n",
    "We are going to use StandardScaler for the numeric features, OrdinalEncoder for the binary ones and OneHotEncoder for the multiple categories. \n",
    "\n",
    "Additionally, in the pipeline builder appart from defining the feature engineering transformations, we will also defin the model and its parameters. we will pack all together in a pipeline and return that.\n",
    "\n",
    "Our pipeline will look like this (well.. in reality the first 3 steps for feature engineering will run in parallel because we defined n_jobs=-1)\n",
    "\n",
    "-> OrdinalEncoder() -> StandardScaler() -> OneHotEncoder() -> CSV() ->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "valid-onion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def pipeline_builder(params_svm: dict, bin_ftr_idx: List[int], num_ftr_idx: List[int], cat_ftr_idx: List[int]) -> Pipeline:\n",
    "    '''\n",
    "    Builds a sklearn pipeline with preprocessing and model configuration.\n",
    "    Preprocessing steps are:\n",
    "        * OrdinalEncoder - used for binary features\n",
    "        * StandardScaler - used for numerical features\n",
    "        * OneHotEncoder - used for categorical features\n",
    "    Model used is SVC\n",
    "\n",
    "            Parameters:\n",
    "                    params_svm (dict): List of parameters for the sklearn.svm.SVC classifier \n",
    "                    bin_ftr_idx (List[str]): List of ints that mark the column indexes with binary columns. i.e [0, 2, ... , X ]\n",
    "                    num_ftr_idx (List[str]): List of ints that mark the column indexes with numerica columns. i.e [6, 3, ... , X ]\n",
    "                    cat_ftr_idx (List[str]): List of ints that mark the column indexes with categorical columns. i.e [5, 10, ... , X ]\n",
    "                    label_column (str): The name of the label column\n",
    "\n",
    "            Returns:\n",
    "                     Pipeline: sklearn.pipelines.Pipeline with preprocessing and model training\n",
    "    '''\n",
    "        \n",
    "    # Definining a preprocessing step for our pipeline. \n",
    "    # it specifies how the features are going to be transformed\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('bin', OrdinalEncoder(), bin_ftr_idx),\n",
    "            ('num', StandardScaler(), num_ftr_idx),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), cat_ftr_idx)], n_jobs=-1)\n",
    "\n",
    "\n",
    "    # We now create a full pipeline, for preprocessing and training.\n",
    "    # for training we selected a linear SVM classifier\n",
    "    clf = SVC()\n",
    "    clf.set_params(**params_svm)\n",
    "    \n",
    "    return Pipeline(steps=[ ('preprocessor', preprocessor),\n",
    "                          ('classifier', clf)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-category",
   "metadata": {},
   "source": [
    "We are going to split our data to  80% training and 20% test sets, and we will create our training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "popular-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\"kernel\":\"linear\", \"C\":2, \"class_weight\":None}\n",
    "clf = pipeline_builder(model_params, BINARY_FEATURES_IDX, NUMERIC_FEATURES_IDX, CATEGORICAL_FEATURES_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-assembly",
   "metadata": {},
   "source": [
    "## Training ML model\n",
    "In the next step we are going to train our model and predict on the test data. We will then use the predictions to evaluate our model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "grand-adams",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pipeline(clf: Pipeline, X: Union[pd.DataFrame, np.ndarray], y: Union[pd.DataFrame, np.ndarray]) -> float:\n",
    "    '''\n",
    "    Trains a sklearn pipeline by fiting training data an labels and returns the accuracy f1 score\n",
    "    \n",
    "            Parameters:\n",
    "                    clf (sklearn.pipelines.Pipeline): the Pipeline object to fit the data\n",
    "                    X: (pd.DataFrame OR np.ndarray): Training vectors of shape n_samples x n_features, where n_samples is the number of samples and n_features is the number of features.\n",
    "                    y: (pd.DataFrame OR np.ndarray): Labels of shape n_samples. Order should mathc Training Vectors X\n",
    "\n",
    "            Returns:\n",
    "                    score (float): Average F1 score from all cross validations\n",
    "    '''\n",
    "    # run cross validation to get training score. we can use this score to optimise training\n",
    "    score = cross_val_score(clf, X, y, cv=10, n_jobs=-1).mean()\n",
    "    \n",
    "    # Now we fit all our data to the classifier. Shame to leave a portion of the data behind\n",
    "    clf.fit(X, y)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "awful-patio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the prediction f1 score average during cross validation is 0.7833058608058608\n"
     ]
    }
   ],
   "source": [
    "cv_score = train_pipeline(clf, X_train, y_train)\n",
    "print(\"the prediction f1 score average during cross validation is {}\".format(cv_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-arbor",
   "metadata": {},
   "source": [
    "# Export Model to Cloud Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-uzbekistan",
   "metadata": {},
   "source": [
    "It is time to export our model to Gloud storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "current-elite",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_gcs_uri(uri: str) -> (str, str, str, str):\n",
    "    '''\n",
    "    Receives a Google Cloud Storage (GCS) uri and breaks it down to the sheme, bucket, path and file\n",
    "    \n",
    "            Parameters:\n",
    "                    uri (str): GCS uri\n",
    "\n",
    "            Returns:\n",
    "                    scheme (str): uri scheme\n",
    "                    bucket (str): uri bucket\n",
    "                    path (str): uri path\n",
    "                    file (str): uri file\n",
    "    '''\n",
    "    url_arr = uri.split(\"/\")\n",
    "    if \".\" not in url_arr[-1]:\n",
    "        file = \"\"\n",
    "    else:\n",
    "        file = url_arr.pop()\n",
    "    scheme = url_arr[0]\n",
    "    bucket = url_arr[2]\n",
    "    path = \"/\".join(url_arr[3:])\n",
    "    path = path[:-1] if path.endswith(\"/\") else path\n",
    "    \n",
    "    return scheme, bucket, path, file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "civic-springfield",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_export_gcs(fitted_pipeline: Pipeline, model_dir: str) -> str:\n",
    "    '''\n",
    "    Exports trained pipeline to GCS\n",
    "    \n",
    "            Parameters:\n",
    "                    fitted_pipeline (sklearn.pipelines.Pipeline): the Pipeline object with data already fitted (trained pipeline object)\n",
    "                    model_dir (str): GCS path to store the trained pipeline. i.e gs://example_bucket/training-job\n",
    "            Returns:\n",
    "                    export_path (str): Model GCS location\n",
    "    '''\n",
    "    scheme, bucket, path, file = process_gcs_uri(model_dir)\n",
    "    if scheme != \"gs:\":\n",
    "            raise ValueError(\"URI scheme must be gs\")\n",
    "    \n",
    "    # Upload the model to GCS\n",
    "    b = storage.Client().bucket(bucket)\n",
    "    export_path = os.path.join(path, 'model.pkl')\n",
    "    blob = b.blob(export_path)\n",
    "    \n",
    "    blob.upload_from_string(pickle.dumps(fitted_pipeline))\n",
    "    return scheme + \"//\" + os.path.join(bucket, export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "floppy-robinson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://myfirstproject-226013/titanic/experiment-20210408-113825/model.pkl'"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_export_gcs(clf, MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-people",
   "metadata": {},
   "source": [
    "## Evaluating model\n",
    "What do you think of this model? Is it accurate enough? Shall we push it to production?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "bigger-screening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86       170\n",
      "           1       0.75      0.72      0.73        92\n",
      "\n",
      "    accuracy                           0.82       262\n",
      "   macro avg       0.80      0.79      0.80       262\n",
      "weighted avg       0.82      0.82      0.82       262\n",
      "\n",
      "\n",
      " Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "print(\"\\n Confusion Matrix\")\n",
    "plot_confusion_matrix(clf, X_test,y_test, normalize='true')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-piano",
   "metadata": {},
   "source": [
    "# Export Classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-metabolism",
   "metadata": {},
   "source": [
    "A model without a report is as good as a teleportation machine without a manual.. \n",
    "\n",
    "You should not try to use it! \n",
    "\n",
    "We must prepare a report and save it with our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "unauthorized-bermuda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_report(cv_score: float, model_params: dict, classification_report: str, columns: List[str], example_data: np.ndarray) -> str:\n",
    "    '''\n",
    "    Prepares a training job repor in Text\n",
    "    \n",
    "            Parameters:\n",
    "                    cv_score (float): score of the training job during cross validation of training data\n",
    "                    model_params (dict): dictonary containing the parameters the model was trained with\n",
    "                    classification_report (str): Model classification report with test data\n",
    "                    columns (List[str]): List of columns that where used in training.\n",
    "                    example_data (np.array): Sample of data (2-3 rows are enough). This is used to include what the prediciton payload should look like for the model\n",
    "            Returns:\n",
    "                    report (str): Full report in text\n",
    "    '''\n",
    "    \n",
    "    buffer_example_data = '['\n",
    "    for r in example_data:\n",
    "        buffer_example_data+='['\n",
    "        for c in r:\n",
    "            if(isinstance(c,str)):\n",
    "                buffer_example_data+=\"'\"+c+\"', \"\n",
    "            else:\n",
    "                buffer_example_data+=str(c)+\", \"\n",
    "        buffer_example_data= buffer_example_data[:-2]+\"], \\n\"\n",
    "    buffer_example_data= buffer_example_data[:-3]+\"]\"\n",
    "        \n",
    "    report = \"\"\"\n",
    "Training Job Report    \n",
    "    \n",
    "Cross Validation Score: {cv_score}\n",
    "\n",
    "Training Model Parameters: {model_params}\n",
    "    \n",
    "Test Data Classification Report:\n",
    "{classification_report}\n",
    "\n",
    "Example of data array for prediciton:\n",
    "\n",
    "Order of columns:\n",
    "{columns}\n",
    "\n",
    "Example for clf.predict()\n",
    "{predict_example}\n",
    "\n",
    "\n",
    "Example of GCP API request body:\n",
    "{{\n",
    "    \"instances\": {json_example}\n",
    "}}\n",
    "\n",
    "\"\"\".format(\n",
    "    cv_score=cv_score,\n",
    "    model_params=json.dumps(model_params),\n",
    "    classification_report=classification_report,\n",
    "    columns = columns,\n",
    "    predict_example = buffer_example_data,\n",
    "    json_example = json.dumps(example_data.tolist()))\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "immediate-level",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_export_gcs(report: str, report_dir: str) -> None:\n",
    "    '''\n",
    "    Exports training job report to GCS\n",
    "    \n",
    "            Parameters:\n",
    "                    report (str): Full report in text to sent to GCS\n",
    "                    report_dir (str): GCS path to store the report model. i.e gs://example_bucket/training-job\n",
    "            Returns:\n",
    "                    export_path (str): Report GCS location\n",
    "    '''\n",
    "    scheme, bucket, path, file = process_gcs_uri(report_dir)\n",
    "    if scheme != \"gs:\":\n",
    "            raise ValueError(\"URI scheme must be gs\")\n",
    "            \n",
    "    # Upload the model to GCS\n",
    "    b = storage.Client().bucket(bucket)\n",
    "    \n",
    "    export_path = os.path.join(path, 'report.pkl')\n",
    "    blob = b.blob(export_path)\n",
    "    \n",
    "    blob.upload_from_string(report)\n",
    "    \n",
    "    return scheme + \"//\" + os.path.join(bucket, export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "novel-thursday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Job Report    \n",
      "    \n",
      "Cross Validation Score: 0.7621978021978022\n",
      "\n",
      "Training Model Parameters: {\"kernel\": \"linear\", \"C\": 2, \"class_weight\": null}\n",
      "    \n",
      "Test Data Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84       170\n",
      "           1       0.78      0.49      0.60        92\n",
      "\n",
      "    accuracy                           0.77       262\n",
      "   macro avg       0.77      0.71      0.72       262\n",
      "weighted avg       0.77      0.77      0.76       262\n",
      "\n",
      "\n",
      "Example of data array for prediciton:\n",
      "\n",
      "Order of columns:\n",
      "['sex', 'age', 'fare', 'pclass', 'embarked', 'home_dest', 'parch', 'sibsp']\n",
      "\n",
      "Example for clf.predict()\n",
      "[['male', 29.8811345124283, 0.0, 2, 'S', 'Belfast', 0, 0], \n",
      "['female', 44.0, 27.7208, 1, 'C', 'Denver, CO', 0, 0]]\n",
      "\n",
      "\n",
      "Example of GCP API request body:\n",
      "{\n",
      "    \"instances\": [[\"male\", 29.8811345124283, 0.0, 2, \"S\", \"Belfast\", 0, 0], [\"female\", 44.0, 27.7208, 1, \"C\", \"Denver, CO\", 0, 0]]\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = prepare_report(cv_score,\n",
    "                        model_params,\n",
    "                        classification_report(y_test,y_pred),\n",
    "                        ALL_COLUMNS, \n",
    "                        X_test.to_numpy()[0:2])\n",
    "\n",
    "report_export_gcs(report, MODEL_DIR)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "respected-symbol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Pipeline does not output the same number of columns as input, so not able to extract model, transformer and assign column names. So setting shap='kernel' to use the (slower and approximate) model-agnostic shap.KernelExplainer. To override  this please pre-process your data yourself and only pass the final model and transformed data to the explainer.\n",
      "For shap='kernel', shap interaction values can unfortunately not be calculated!\n",
      "Note: shap values for shap='kernel' normally get calculated against X_background, but paramater X_background=None, so setting X_background=shap.sample(X, 50)...\n",
      "Generating self.shap_explainer = shap.KernelExplainer(model, X, link='identity')\n"
     ]
    }
   ],
   "source": [
    "from explainerdashboard import ClassifierExplainer, ExplainerDashboard\n",
    "explainer = ClassifierExplainer(clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "seventh-television",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ExplainerDashboard..\n",
      "Detected notebook environment, consider setting mode='external', mode='inline' or mode='jupyterlab' to keep the notebook interactive while the dashboard is running...\n",
      "For this type of model and model_output interactions don't work, so setting shap_interaction=False...\n",
      "The explainer object has no decision_trees property. so setting decision_trees=False...\n",
      "Generating layout...\n",
      "Calculating shap values...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4816efd5c6a441b9ea4f9ee88f5fcde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/262 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dependencies...\n",
      "Calculating permutation importances (if slow, try setting n_jobs parameter)...\n",
      "Calculating prediction probabilities...\n",
      "Calculating classification_dfs...\n",
      "Calculating liftcurve_dfs...\n",
      "Calculating pr auc curves...\n",
      "Calculating predictions...\n",
      "Calculating roc auc curves...\n",
      "Calculating confusion matrices...\n",
      "Calculating pred_percentiles...\n",
      "Calculating metrics...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n",
      "Starting ExplainerDashboard on http://10.138.0.39:8050\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 98] Address already in use",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-220-9aca37fc19ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mExplainerDashboard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexplainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/explainerdashboard/dashboards.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, port, host, use_waitress, mode, **kwargs)\u001b[0m\n\u001b[1;32m    850\u001b[0m                 \u001b[0mserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m                 \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'dash'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/dash/dash.py\u001b[0m in \u001b[0;36mrun_server\u001b[0;34m(self, host, port, proxy, debug, dev_tools_ui, dev_tools_props_check, dev_tools_serve_dev_bundles, dev_tools_hot_reload, dev_tools_hot_reload_interval, dev_tools_hot_reload_watch_interval, dev_tools_hot_reload_max_retry, dev_tools_silence_routes_logging, dev_tools_prune_errors, **flask_run_options)\u001b[0m\n\u001b[1;32m   1715\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dash is running on %s://%s%s%s\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdisplay_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mflask_run_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/flask/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, host, port, debug, load_dotenv, **options)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mrun_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m             \u001b[0;31m# reset the first request information if the development server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/werkzeug/serving.py\u001b[0m in \u001b[0;36mrun_simple\u001b[0;34m(hostname, port, application, use_reloader, use_debugger, use_evalex, extra_files, reloader_interval, reloader_type, threaded, processes, request_handler, static_files, passthrough_errors, ssl_context)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0mrun_with_reloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreloader_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreloader_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m         \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/werkzeug/serving.py\u001b[0m in \u001b[0;36minner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0mpassthrough_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m             \u001b[0mssl_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1005\u001b[0;31m             \u001b[0mfd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1006\u001b[0m         )\n\u001b[1;32m   1007\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfd\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/werkzeug/serving.py\u001b[0m in \u001b[0;36mmake_server\u001b[0;34m(host, port, app, threaded, processes, request_handler, passthrough_errors, ssl_context, fd)\u001b[0m\n\u001b[1;32m    846\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mthreaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m         return ThreadedWSGIServer(\n\u001b[0;32m--> 848\u001b[0;31m             \u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassthrough_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mssl_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m         )\n\u001b[1;32m    850\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprocesses\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/werkzeug/serving.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, host, port, app, handler, passthrough_errors, ssl_context, fd)\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress_family\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0maf_unix\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m         \u001b[0mHTTPServer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_address\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/socketserver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, server_address, RequestHandlerClass, bind_and_activate)\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbind_and_activate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_activate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/http/server.py\u001b[0m in \u001b[0;36mserver_bind\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mserver_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;34m\"\"\"Override server_bind to store the server name.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0msocketserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTCPServer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_address\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetfqdn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/socketserver.py\u001b[0m in \u001b[0;36mserver_bind\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_reuse_address\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetsockopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOL_SOCKET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSO_REUSEADDR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_address\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsockname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 98] Address already in use"
     ]
    }
   ],
   "source": [
    "ExplainerDashboard(explainer).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "documented-elizabeth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"800\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f9905f0a1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-178-e9b1ffc01ceb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexplainerdashboard\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInlineExplainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mInlineExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexplainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdependence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "from explainerdashboard import InlineExplainer\n",
    "\n",
    "InlineExplainer(explainer).shap.dependence()()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "announced-blackberry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"800\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f9905ec5090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "InlineExplainer(explainer).shap.overview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "dressed-range",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method InlineExplainerTabs.importances of InlineExplainer.tabs has the following components: contributions, decisiontrees, dependence, importances, interactions, modelsummary, whatif>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "InlineExplainer(explainer).tab.importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-hollywood",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.mnightly-2021-02-02-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:mnightly-2021-02-02-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
